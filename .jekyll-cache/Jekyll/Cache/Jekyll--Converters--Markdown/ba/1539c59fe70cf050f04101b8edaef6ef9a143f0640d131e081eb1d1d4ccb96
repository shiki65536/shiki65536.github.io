I"ñ<p>Duplication is not Duplicationâ€Šâ€”â€ŠThe Kafka Connect S3 Sink IdentityÂ CrisisThis week I finally understood what â€œduplicationâ€ really means in S3Â Sink.Wrong test:Set <code class="language-plaintext highlighter-rouge">flush.size=1</code> â†’ â€œSpam the same payload every minute viaÂ AKHQâ€Senior:â€œThatâ€™s not duplication. Duplication = same Kafka record (topic+partition+offset) processed twice.â€The moment I realized <strong>Payload is not Offset</strong>, everything clicked.Real duplication triggers:Task crash before offsetÂ commitRebalance steals partition earlyPoll timeout after processingAll produce identical records â†’ connector can writeÂ twice.My old config (95%Â safe):flush.size=1rotate.schedule.interval.ms=null # explicitly disabled (never use it for per-message sinks)# no rotate.interval.ms â†’ tiny risk windowpartition.field.name=order_idBulletproof config (2025 standard):flush.size=1rotate.schedule.interval.ms=null # explicitly disabled (never use it for per-message sinks)rotate.interval.ms=30000 # 30 seconds sweet spotpartition.field.name=order_idTL;DRSame payload â‰  duplicationSame offset twice = duplicationflush.size=1 + rotate.interval.ms=30000 + explicit rotate.schedule.interval.ms=null = sleep peacefully.</p>
:ET