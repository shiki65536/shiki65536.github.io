---
layout: default
title: " Duplication â‰  Duplicationâ€Šâ€”â€ŠThe Kafka Connect S3 Sink Identity Crisis"
date: Sun, 30 Nov 2025 09:45:59 +0000
excerpt: "ğŸ¤¯ Duplication â‰  Duplicationâ€Šâ€”â€Š"
link: "https://medium.com/@shiki65536/duplication-duplication-the-kafka-connect-s3-sink-identity-crisis-aae63969e215?source=rss-374d8f1302a3------2"
image: "https://cdn-images-1.medium.com/max/500/1*Y1hf9VCKk6lwF-Yb9vUDeg.jpeg"
tags: ["s3", "kafka-connect", "kafka"]
---
ğŸ¤¯ Duplication â‰  Duplicationâ€Šâ€”â€ŠThe Kafka Connect S3 Sink IdentityÂ CrisisThis week I finally understood what â€œduplicationâ€ really means in S3Â Sink.Wrong test:Set `flush.size=1` â†’ â€œSpam the same payload every minute viaÂ AKHQâ€Senior:â€œThatâ€™s not duplication. Duplication = same Kafka record (topic+partition+offset) processed twice.â€The moment I realized **Payload â‰  Offset**, everything clicked.Real duplication triggers:Task crash before offsetÂ commitRebalance steals partition earlyPoll timeout after processingAll produce identical records â†’ connector can writeÂ twice.My old config (95%Â safe):flush.size=1rotate.schedule.interval.ms=null # explicitly disabled (never use it for per-message sinks)# no rotate.interval.ms â†’ tiny risk windowpartition.field.name=order_idBulletproof config (2025 standard):flush.size=1rotate.schedule.interval.ms=null # explicitly disabled (never use it for per-message sinks)rotate.interval.ms=30000 # 30 seconds sweet spotpartition.field.name=order_idTL;DRSame payload â‰  duplicationSame offset twice = duplicationflush.size=1 + rotate.interval.ms=30000 + explicit rotate.schedule.interval.ms=null = sleep peacefully.
